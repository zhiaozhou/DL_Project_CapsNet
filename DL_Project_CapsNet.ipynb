{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:10.386684Z",
     "start_time": "2018-04-23T23:42:08.729769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:10.408110Z",
     "start_time": "2018-04-23T23:42:10.396822Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment the images\n",
    "def augmentation(x, max_offset=2):\n",
    "    bz, h, w, c = x.shape\n",
    "    bg = np.zeros([bz, w + 2 * max_offset, h + 2 * max_offset, c])\n",
    "    offsets = np.random.randint(0, 2 * max_offset + 1, 2)\n",
    "    #shift\n",
    "    bg[:, offsets[0]:offsets[0] + h, offsets[1]:offsets[1] + w, :] = x\n",
    "    return bg[:, max_offset:max_offset + h, max_offset:max_offset + w, :]\n",
    "\n",
    "#mini-batch for single digit training set\n",
    "def mnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        # the output is a batch of train set, with 28*28*3 for each pic and 10*3 label for corresponding pic. Shift is possible.\n",
    "\n",
    "#mini-batch for single digit test set\n",
    "def mnist_test_iter(iters=1000, batch_size=32, is_shift_ag=False):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.test.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        \n",
    "#mini-batch for overlapping digit training set\n",
    "def multimnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch1 = mnist.train.next_batch(batch_size)\n",
    "        batch2 = mnist.train.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "\n",
    "#mini-batch for overlapping digit test set\n",
    "def multimnist_test_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        #two batch at one iter\n",
    "        batch1 = mnist.test.next_batch(batch_size)\n",
    "        batch2 = mnist.test.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        #overlapping\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "        #size of result is 32*28*28*3, here data in same pos of pics with same index, will be put into one inner array\n",
    "        #sequence of shift and concatenate is reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:11.334321Z",
     "start_time": "2018-04-23T23:42:11.302412Z"
    }
   },
   "outputs": [],
   "source": [
    "# A CapsNet class is initiated here to assemble the process of prediction and validation.\n",
    "# 1. The input is a batch of pics, we need to split the input into 3 different batches\n",
    "# 2. Use get_CapsNet function\n",
    "# 2.1 to reach the output layer, with two hidden layer\n",
    "# 2.2 use process of dynamic routing, do it in iteration, update the output vector\n",
    "# 3. Use get_mlp_decoder function\n",
    "# 3.1 for each predicted output and real label, use get_mlp_decoder to reconstruct the input pics\n",
    "# 4. Cal the difference between reconstructed pics and real pics. Use function to cal the loss and accuracy.\n",
    "# when we init a class, and input the batches, we could acquire the accuracy from classâ€™s variables.\n",
    "\n",
    "class CapsNet(object):\n",
    "    def __init__(self,\n",
    "                 routing_iterations=3,\n",
    "                 batch_size=128,\n",
    "                 is_multi_mnist=True,\n",
    "                 steps=5000,\n",
    "                 norm=True,\n",
    "                 lr_find=False):\n",
    "        \"\"\"\n",
    "        routing_iterations: iterations for routing in CapsNet\n",
    "        batch_size: data size for every batch\n",
    "        is_multi_mnist: if it's for single or overlapping image\n",
    "        steps: epochs \n",
    "        norm: if batch_normalization or not\n",
    "        \"\"\"\n",
    "        self.iterations = routing_iterations\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Single or overlapping image\n",
    "        self.is_multi_mnist = float(is_multi_mnist)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 10, 3])\n",
    "        \n",
    "        if lr_find:\n",
    "            self.lr = tf.placeholder(tf.float32)\n",
    "        else:\n",
    "            #use a exponentially decayed learninig rate\n",
    "            global_step = tf.Variable(0)\n",
    "            lr = tf.train.exponential_decay(\n",
    "                0.00075, global_step, steps / 10, 0.96, staircase=False)\n",
    "        self.norm = norm\n",
    "        self.on_train = tf.placeholder(tf.bool)\n",
    "\n",
    "        x_composed, x_a, x_b = tf.split(self.x, num_or_size_splits=3, axis=3)\n",
    "        y_composed, y_a, y_b = tf.split(self.y, num_or_size_splits=3, axis=2)\n",
    "    \n",
    "        #if not overlapping, mask = tf.ones_like(y_composed[:,0,0])\n",
    "        #if overlapping: mask = tf.reduce_sum(y_composed, axis=[1,2]) - 1.0\n",
    "        #for not overlapping: ones_like will generate the array of 1 the same size as input array. Here y_composed[:,0,0], each pic choose only 1 pos, therefore, it is a 1 dimension vector, the size equals batch_size.\n",
    "        #for overlapping: reduce_sum will sum all num in a range. Here, we choose [1, 2], which is all label for a particular pic. Therefore, reduce_sum here will sum label for each pic in the batch, will represent the num of digits in each pic.\n",
    "        valid_mask = self.is_multi_mnist * (tf.reduce_sum(y_composed, axis=[1,2]) - 1.0) \\\n",
    "                      + (1.0 - self.is_multi_mnist) * tf.ones_like(y_composed[:,0,0])\n",
    "        \n",
    "        #reg_term is the penalty term\n",
    "        v_digit,reg_term = self.get_CapsNet(x_composed, self.norm, self.on_train)\n",
    "\n",
    "        length_v = tf.reduce_sum(v_digit**2.0, axis=-1)**0.5\n",
    "\n",
    "        x_rec_a = self.get_mlp_decoder(v_digit * y_a)\n",
    "        x_rec_b = self.get_mlp_decoder(v_digit * y_b, reuse=True)\n",
    "        loss_rec_a = tf.reduce_sum((x_rec_a - x_a)**2.0, axis=[1, 2, 3])\n",
    "        loss_rec_b = tf.reduce_sum((x_rec_b - x_b)**2.0, axis=[1, 2, 3])\n",
    "        self.loss_rec = (loss_rec_a + loss_rec_b) / 2.0\n",
    "        \n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            y_composed[:, :, 0] * tf.maximum(0.0, 0.9 - length_v)**2.0 + 0.5 *\n",
    "            (1.0 - y_composed[:, :, 0]) * tf.maximum(0.0, length_v - 0.1)**2.0,\n",
    "            axis=-1)\n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            self.loss_cls * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_cls: batch_size, valid_mask: _batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #sum2: num of digits for all pics in the batch\n",
    "        #cal the loss percentage considering y_composed (real label)\n",
    "        \n",
    "        self.loss_rec = tf.reduce_sum(\n",
    "            self.loss_rec * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_rec: batch_size, valid_mask: batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #cal the loss percentage considering prediction from x_composed, x_a, x_b\n",
    "        \n",
    "        #loss with the penalty term\n",
    "        self.loss = self.loss_cls + 0.0005 * self.loss_rec + reg_term\n",
    "        \n",
    "        #adam optimizer\n",
    "        if lr_find:\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "        else:\n",
    "            self.train = tf.train.AdamOptimizer(\n",
    "                learning_rate=lr).minimize(\n",
    "                    self.loss, global_step=global_step)\n",
    "\n",
    "        #accuracy for single and overlapping training data\n",
    "        if is_multi_mnist:\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_a), 1),k=2),tf.float32))+\\\n",
    "                            tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_b), 1),k=2),tf.float32))\n",
    "            self.accuracy /= 2.0\n",
    "        else:\n",
    "            correct_prediction = tf.equal(\n",
    "                tf.argmax(y_composed[:, :, 0], 1), tf.argmax(length_v, 1))\n",
    "            self.accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def get_CapsNet(self, x, norm, on_train, reuse=False):\n",
    "        \"\"\"\n",
    "        norm: to use batch-normalization or not\n",
    "        on_train: if it's for train or test\n",
    "        \"\"\"\n",
    "        #Two conv layers and a capsule layer\n",
    "        with tf.variable_scope('CapsNet', reuse=reuse):\n",
    "            wconv1 = tf.get_variable(\n",
    "                'wconv1', [9, 9, 1, 256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv1 = tf.get_variable(\n",
    "                'bconv1', [256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wconv2 = tf.get_variable(\n",
    "                'wconv2', [9, 9, 256, 8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv2 = tf.get_variable(\n",
    "                'bconv2', [8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wcap = tf.get_variable(\n",
    "                'wcap', [1, 6, 6, 32, 8, 10, 16],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b = tf.get_variable(\n",
    "                'coupling_coefficient_logits', [1, 6, 6, 32, 1, 10, 1],\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        #use stop_gradient for debug\n",
    "        c = tf.stop_gradient(tf.nn.softmax(b, axis=5))\n",
    "        \n",
    "        #L2-regularization\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv1)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv2)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wcap)\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "        \n",
    "        if norm:\n",
    "            # BN for the first input\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                x,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                \"\"\"\n",
    "                update mean and variance using moving average\n",
    "                \"\"\"\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "            \n",
    "            # if it's for test, then don't update mean and var, instead use the fc_mean and fc_var that already calculated\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            x = tf.nn.batch_normalization(x, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        conv1 = tf.nn.conv2d(x, wconv1, [1, 1, 1, 1], padding='VALID') + bconv1\n",
    "\n",
    "        if norm:\n",
    "            # BN for the first conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv1,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv1 = tf.nn.batch_normalization(conv1, mean, var, shift, scale,\n",
    "                                              epsilon)\n",
    "\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "        s_primary = tf.nn.conv2d(\n",
    "            conv1, wconv2, [1, 2, 2, 1], padding='VALID') + bconv2\n",
    "\n",
    "        if norm:\n",
    "            # BN for the second conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                s_primary,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            s_primary = tf.nn.batch_normalization(s_primary, mean, var, shift,\n",
    "                                                  scale, epsilon)\n",
    "\n",
    "        s_primary = tf.reshape(s_primary, [-1, 6, 6, 32, 8, 1, 1])\n",
    "        #change form from batch_size*6*6*256 into -1*6*6*32*8*1*1. For input of capsule, it contains 6*6*32 vectors, each vector has 8 elements. We could consider it as reshape the 256 output layer into 8 groups, each group contains 32 layer. Put 8 groups parallel and each vector is the pix in same positions in 8 groups. \n",
    "        #the use of 1, 1 will make it easy to cal when we do u*wcap in the following step. (* is the multiply by elements in corresponding pos) (expand automatically, but we need to keep same dimensions first)\n",
    "\n",
    "        v_primary = self.squash(s_primary, axis=4)\n",
    "\n",
    "        #CAPSNET\n",
    "        u = v_primary #input of capsule\n",
    "        u_ = tf.reduce_sum(u * wcap, axis=[4], keepdims=True)\n",
    "        s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "        v = self.squash(s, axis=-1)\n",
    "\n",
    "        if norm:\n",
    "            # BN for the capsule layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                v,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            v = tf.nn.batch_normalization(v, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        for i in range(self.iterations - 1):\n",
    "            b += tf.reduce_sum(u_ * v, axis=-1, keepdims=True)\n",
    "            c = tf.nn.softmax(b, axis=5)\n",
    "            s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "            v = self.squash(s, axis=-1) #get the correct v\n",
    "\n",
    "        v_digit = tf.squeeze(v)\n",
    "\n",
    "        return v_digit,reg_term\n",
    "\n",
    "    def get_mlp_decoder(self, h, num_h=[10 * 16, 512, 1024, 784], reuse=False):\n",
    "        \"\"\"\n",
    "        restruction the input images: 160 -> 512 -> 1024 -> 784\n",
    "        \"\"\"\n",
    "        h = tf.reshape(h, [-1, 10 * 16])\n",
    "        with tf.variable_scope('decoder', reuse=reuse):\n",
    "            weights = []\n",
    "            for i in range(len(num_h) - 1):\n",
    "                w = tf.get_variable(\n",
    "                    'wfc%d' % i, [num_h[i], num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                b = tf.get_variable(\n",
    "                    'bfc%d' % i, [num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                weights.append((w, b))\n",
    "                if i < len(num_h) - 2:\n",
    "                    h = tf.nn.relu(tf.add(tf.matmul(h, w), b))\n",
    "                else:\n",
    "                    h = tf.nn.sigmoid(tf.add(tf.matmul(h, w), b))\n",
    "        x_rec = tf.reshape(h, [-1, 28, 28, 1])\n",
    "        return x_rec\n",
    "\n",
    "    def squash(self, s, axis=-1):\n",
    "        length_s = tf.reduce_sum(s**2.0, axis=axis, keepdims=True)**0.5\n",
    "        v = s * length_s / (1.0 + length_s**2.0) #shorten the length of each vector, make the length a little shorter than 1. Non-linear. To avoid the existence of 0 vector.\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:12.523507Z",
     "start_time": "2018-04-23T23:42:12.519523Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "is_multi_mnist = True\n",
    "is_shift_ag = True\n",
    "irun = 0\n",
    "steps = 3000\n",
    "lr_find = False\n",
    "lr_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first try to find the best lr by increasing it by every iter and see at what iter the corresponding lr is doing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:32:32.027961Z",
     "start_time": "2018-04-09T01:32:32.024607Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = True\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:19.388102Z",
     "start_time": "2018-04-09T01:32:32.721926Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "    \n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run([net.loss, net.loss_rec, net.accuracy, net.train], feed_dict={net.x: X, net.y: Y, net.on_train:True ,net.lr: lr})\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5,1e-2,steps)[2]-np.linspace(1e-5,1e-2,steps)[1]   \n",
    "        \n",
    "    else:    \n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST)\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:32.033332Z",
     "start_time": "2018-04-09T01:36:31.274615Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(lr_list,loss_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the figure above, we are going to let lr = 0.00075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:16.260921Z",
     "start_time": "2018-04-23T23:42:16.257871Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = False\n",
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:42:16.686412Z",
     "start_time": "2018-04-23T23:42:16.683111Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:50:27.789903Z",
     "start_time": "2018-04-23T23:42:29.231234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 1.6449453 0.203125 0.3125 1.927839756011963s per epoch\n",
      "100 0.63865465 0.6328125 0.7578125 0.09208464622497559s per epoch\n",
      "200 0.56094456 0.703125 0.8046875 0.09055590629577637s per epoch\n",
      "300 0.5324198 0.7265625 0.71875 0.0910651683807373s per epoch\n",
      "400 0.48229676 0.765625 0.6953125 0.09103846549987793s per epoch\n",
      "500 0.4376002 0.78125 0.8203125 0.09258031845092773s per epoch\n",
      "600 0.427149 0.78125 0.6171875 0.09038019180297852s per epoch\n",
      "700 0.42090768 0.796875 0.84375 0.09222531318664551s per epoch\n",
      "800 0.41683176 0.8046875 0.8125 0.09190869331359863s per epoch\n",
      "900 0.35109386 0.8359375 0.8046875 0.09123611450195312s per epoch\n",
      "Model Saved!\n",
      "1000 0.3682449 0.8515625 0.71875 0.09205055236816406s per epoch\n",
      "1100 0.362899 0.859375 0.7421875 0.09153532981872559s per epoch\n",
      "1200 0.33650255 0.828125 0.828125 0.09320616722106934s per epoch\n",
      "1300 0.37525874 0.828125 0.7578125 0.0930333137512207s per epoch\n",
      "1400 0.36691388 0.8125 0.8828125 0.09352278709411621s per epoch\n",
      "1500 0.32444847 0.828125 0.8046875 0.09303569793701172s per epoch\n",
      "1600 0.3765568 0.8125 0.75 0.09383702278137207s per epoch\n",
      "1700 0.35508558 0.8359375 0.890625 0.09236431121826172s per epoch\n",
      "1800 0.3149807 0.8671875 0.734375 0.09489274024963379s per epoch\n",
      "1900 0.30072358 0.8359375 0.8828125 0.0929250717163086s per epoch\n",
      "Model Saved!\n",
      "2000 0.30697468 0.8515625 0.8671875 0.09352397918701172s per epoch\n",
      "2100 0.31935242 0.84375 0.828125 0.09591817855834961s per epoch\n",
      "2200 0.29866573 0.8671875 0.890625 0.09373593330383301s per epoch\n",
      "2300 0.28171667 0.90625 0.8515625 0.09409594535827637s per epoch\n",
      "2400 0.3543085 0.8359375 0.6640625 0.09381246566772461s per epoch\n",
      "2500 0.3242471 0.8359375 0.796875 0.10409879684448242s per epoch\n",
      "2600 0.2782012 0.8828125 0.7890625 0.09318041801452637s per epoch\n",
      "2700 0.32404083 0.8671875 0.765625 0.09076952934265137s per epoch\n",
      "2800 0.29797065 0.8671875 0.859375 0.09199166297912598s per epoch\n",
      "2900 0.30082864 0.8671875 0.8671875 0.09503674507141113s per epoch\n",
      "Model Saved!\n",
      "3000 0.3784815 0.796875 0.8671875 0.09362936019897461s per epoch\n",
      "3100 0.29695353 0.8671875 0.828125 0.09352397918701172s per epoch\n",
      "3200 0.3101849 0.859375 0.703125 0.0944678783416748s per epoch\n",
      "3300 0.30272028 0.8515625 0.8515625 0.09378504753112793s per epoch\n",
      "3400 0.30810687 0.875 0.8671875 0.09409022331237793s per epoch\n",
      "3500 0.29172528 0.8828125 0.8671875 0.09253501892089844s per epoch\n",
      "3600 0.23457357 0.90625 0.8671875 0.09307193756103516s per epoch\n",
      "3700 0.2560801 0.8984375 0.828125 0.09383916854858398s per epoch\n",
      "3800 0.27991337 0.875 0.6953125 0.0930778980255127s per epoch\n",
      "3900 0.37343436 0.8203125 0.7578125 0.09242033958435059s per epoch\n",
      "Model Saved!\n",
      "4000 0.34534496 0.8203125 0.859375 0.09383845329284668s per epoch\n",
      "4100 0.25611407 0.9140625 0.8828125 0.09298563003540039s per epoch\n",
      "4200 0.28261843 0.8828125 0.8984375 0.09335827827453613s per epoch\n",
      "4300 0.24867597 0.9140625 0.7109375 0.09393167495727539s per epoch\n",
      "4400 0.3081984 0.875 0.7890625 0.09249615669250488s per epoch\n",
      "4500 0.30067226 0.8359375 0.875 0.09129858016967773s per epoch\n",
      "4600 0.27187347 0.890625 0.8359375 0.09391140937805176s per epoch\n",
      "4700 0.32855237 0.8515625 0.796875 0.09270882606506348s per epoch\n",
      "4800 0.2589394 0.9140625 0.828125 0.0929415225982666s per epoch\n",
      "4900 0.28562996 0.875 0.875 0.09307122230529785s per epoch\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#For model saving\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    a = time.time()\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "\n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True,\n",
    "                net.lr: lr\n",
    "            })\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5, 1e-2, steps)[2] - np.linspace(\n",
    "            1e-5, 1e-2, steps)[1]\n",
    "\n",
    "    else:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        b = time.time()\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST, '{}s per epoch'.format(b - a))\n",
    "\n",
    "        if (irun + 1) % 1000 == 0:\n",
    "            saver.save(sess, \"./checkpoint_CapsNet/MyModel\")\n",
    "            print('Model Saved!')\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
