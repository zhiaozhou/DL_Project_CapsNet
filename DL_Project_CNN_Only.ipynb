{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:31.700212Z",
     "start_time": "2018-04-23T23:34:29.984354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:31.778027Z",
     "start_time": "2018-04-23T23:34:31.765149Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment the images\n",
    "def augmentation(x, max_offset=2):\n",
    "    bz, h, w, c = x.shape\n",
    "    bg = np.zeros([bz, w + 2 * max_offset, h + 2 * max_offset, c])\n",
    "    offsets = np.random.randint(0, 2 * max_offset + 1, 2)\n",
    "    #shift\n",
    "    bg[:, offsets[0]:offsets[0] + h, offsets[1]:offsets[1] + w, :] = x\n",
    "    return bg[:, max_offset:max_offset + h, max_offset:max_offset + w, :]\n",
    "\n",
    "#mini-batch for single digit training set\n",
    "def mnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        # the output is a batch of train set, with 28*28*3 for each pic and 10*3 label for corresponding pic. Shift is possible.\n",
    "\n",
    "#mini-batch for single digit test set\n",
    "def mnist_test_iter(iters=1000, batch_size=32, is_shift_ag=False):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.test.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        \n",
    "#mini-batch for overlapping digit training set\n",
    "def multimnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch1 = mnist.train.next_batch(batch_size)\n",
    "        batch2 = mnist.train.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "\n",
    "#mini-batch for overlapping digit test set\n",
    "def multimnist_test_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        #two batch at one iter\n",
    "        batch1 = mnist.test.next_batch(batch_size)\n",
    "        batch2 = mnist.test.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        #overlapping\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "        #size of result is 32*28*28*3, here data in same pos of pics with same index, will be put into one inner array\n",
    "        #sequence of shift and concatenate is reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:31.869923Z",
     "start_time": "2018-04-23T23:34:31.841640Z"
    }
   },
   "outputs": [],
   "source": [
    "# A CapsNet class is initiated here to assemble the process of prediction and validation.\n",
    "# 1. The input is a batch of pics, we need to split the input into 3 different batches\n",
    "# 2. Use get_CapsNet function\n",
    "# 2.1 to reach the output layer, with two hidden layer\n",
    "# 2.2 use process of dynamic routing, do it in iteration, update the output vector\n",
    "# 3. Use get_mlp_decoder function\n",
    "# 3.1 for each predicted output and real label, use get_mlp_decoder to reconstruct the input pics\n",
    "# 4. Cal the difference between reconstructed pics and real pics. Use function to cal the loss and accuracy.\n",
    "# when we init a class, and input the batches, we could acquire the accuracy from classâ€™s variables.\n",
    "\n",
    "class CapsNet(object):\n",
    "    def __init__(self,\n",
    "                 routing_iterations=3,\n",
    "                 batch_size=128,\n",
    "                 is_multi_mnist=True,\n",
    "                 steps=5000,\n",
    "                 norm=True,\n",
    "                 lr_find=False):\n",
    "        \"\"\"\n",
    "        routing_iterations: iterations for routing in CapsNet\n",
    "        batch_size: data size for every batch\n",
    "        is_multi_mnist: if it's for single or overlapping image\n",
    "        steps: epochs \n",
    "        norm: if batch_normalization or not\n",
    "        \"\"\"\n",
    "        self.iterations = routing_iterations\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Single or overlapping image\n",
    "        self.is_multi_mnist = float(is_multi_mnist)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 10, 3])\n",
    "        \n",
    "        if lr_find:\n",
    "            self.lr = tf.placeholder(tf.float32)\n",
    "        else:\n",
    "            #use a exponentially decayed learninig rate\n",
    "            global_step = tf.Variable(0)\n",
    "            lr = tf.train.exponential_decay(\n",
    "                0.00015, global_step, steps / 10, 0.96, staircase=False)\n",
    "        self.norm = norm\n",
    "        self.on_train = tf.placeholder(tf.bool)\n",
    "\n",
    "        x_composed, x_a, x_b = tf.split(self.x, num_or_size_splits=3, axis=3)\n",
    "        y_composed, y_a, y_b = tf.split(self.y, num_or_size_splits=3, axis=2)\n",
    "    \n",
    "        #if not overlapping, mask = tf.ones_like(y_composed[:,0,0])\n",
    "        #if overlapping: mask = tf.reduce_sum(y_composed, axis=[1,2]) - 1.0\n",
    "        #for not overlapping: ones_like will generate the array of 1 the same size as input array. Here y_composed[:,0,0], each pic choose only 1 pos, therefore, it is a 1 dimension vector, the size equals batch_size.\n",
    "        #for overlapping: reduce_sum will sum all num in a range. Here, we choose [1, 2], which is all label for a particular pic. Therefore, reduce_sum here will sum label for each pic in the batch, will represent the num of digits in each pic.\n",
    "        valid_mask = self.is_multi_mnist * (tf.reduce_sum(y_composed, axis=[1,2]) - 1.0) \\\n",
    "                      + (1.0 - self.is_multi_mnist) * tf.ones_like(y_composed[:,0,0])\n",
    "        \n",
    "        #reg_term is the penalty term\n",
    "        v_digit,reg_term = self.get_CapsNet(x_composed, self.norm, self.on_train)\n",
    "\n",
    "        length_v = tf.reduce_sum(v_digit**2.0, axis=-1)**0.5\n",
    "\n",
    "        x_rec_a = self.get_mlp_decoder(v_digit * y_a)\n",
    "        x_rec_b = self.get_mlp_decoder(v_digit * y_b, reuse=True)\n",
    "        loss_rec_a = tf.reduce_sum((x_rec_a - x_a)**2.0, axis=[1, 2, 3])\n",
    "        loss_rec_b = tf.reduce_sum((x_rec_b - x_b)**2.0, axis=[1, 2, 3])\n",
    "        self.loss_rec = (loss_rec_a + loss_rec_b) / 2.0\n",
    "        \n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            y_composed[:, :, 0] * tf.maximum(0.0, 0.9 - length_v)**2.0 + 0.5 *\n",
    "            (1.0 - y_composed[:, :, 0]) * tf.maximum(0.0, length_v - 0.1)**2.0,\n",
    "            axis=-1)\n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            self.loss_cls * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_cls: batch_size, valid_mask: _batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #sum2: num of digits for all pics in the batch\n",
    "        #cal the loss percentage considering y_composed (real label)\n",
    "        \n",
    "        self.loss_rec = tf.reduce_sum(\n",
    "            self.loss_rec * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_rec: batch_size, valid_mask: batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #cal the loss percentage considering prediction from x_composed, x_a, x_b\n",
    "        \n",
    "        #loss with the penalty term\n",
    "        self.loss = self.loss_cls + 0.0005 * self.loss_rec + reg_term\n",
    "        \n",
    "        #adam optimizer\n",
    "        if lr_find:\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "        else:\n",
    "            self.train = tf.train.AdamOptimizer(\n",
    "                learning_rate=lr).minimize(\n",
    "                    self.loss, global_step=global_step)\n",
    "\n",
    "        #accuracy for single and overlapping training data\n",
    "        if is_multi_mnist:\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_a), 1),k=2),tf.float32))+\\\n",
    "                            tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_b), 1),k=2),tf.float32))\n",
    "            self.accuracy /= 2.0\n",
    "        else:\n",
    "            correct_prediction = tf.equal(\n",
    "                tf.argmax(y_composed[:, :, 0], 1), tf.argmax(length_v, 1))\n",
    "            self.accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def get_CapsNet(self, x, norm, on_train, reuse=False):\n",
    "        \"\"\"\n",
    "        norm: to use batch-normalization or not\n",
    "        on_train: if it's for train or test\n",
    "        \"\"\"\n",
    "        #Two conv layers and a capsule layer\n",
    "        with tf.variable_scope('CapsNet', reuse=reuse):\n",
    "            wconv1 = tf.get_variable(\n",
    "                'wconv1', [9, 9, 1, 256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv1 = tf.get_variable(\n",
    "                'bconv1', [256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wconv2 = tf.get_variable(\n",
    "                'wconv2', [9, 9, 256, 8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv2 = tf.get_variable(\n",
    "                'bconv2', [8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wconv3 = tf.get_variable(\n",
    "                'wconv3', [3, 3, 256, 10],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv3 = tf.get_variable(\n",
    "                'bconv3', [10],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        \n",
    "        \n",
    "        #L2-regularization\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv1)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv2)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv3)\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "        \n",
    "        if norm:\n",
    "            # BN for the first input\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                x,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                \"\"\"\n",
    "                update mean and variance using moving average\n",
    "                \"\"\"\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "            \n",
    "            # if it's for test, then don't update mean and var, instead use the fc_mean and fc_var that already calculated\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            x = tf.nn.batch_normalization(x, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        conv1 = tf.nn.conv2d(x, wconv1, [1, 1, 1, 1], padding='VALID') + bconv1\n",
    "\n",
    "        if norm:\n",
    "            # BN for the first conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv1,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv1 = tf.nn.batch_normalization(conv1, mean, var, shift, scale,\n",
    "                                              epsilon)\n",
    "\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "        conv2 = tf.nn.conv2d(\n",
    "            conv1, wconv2, [1, 2, 2, 1], padding='VALID') + bconv2\n",
    "\n",
    "        if norm:\n",
    "            # BN for the second conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv2,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv2 = tf.nn.batch_normalization(conv2, mean, var, shift,\n",
    "                                                  scale, epsilon)\n",
    "\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "        conv3 = tf.nn.conv2d(\n",
    "            conv2, wconv3, [1, 1, 1, 1], padding='VALID') + bconv3\n",
    "\n",
    "        if norm:\n",
    "            # BN for the capsule layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv3,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv3 = tf.nn.batch_normalization(conv3, mean, var, shift, scale, epsilon)\n",
    "\n",
    "\n",
    "        v_digit = tf.reshape(tf.nn.relu(conv3),[-1,10,16])\n",
    "        \n",
    "        \n",
    "        return v_digit,reg_term\n",
    "\n",
    "    def get_mlp_decoder(self, h, num_h=[10 * 16, 512, 1024, 784], reuse=False):\n",
    "        \"\"\"\n",
    "        restruction the input images: 160 -> 512 -> 1024 -> 784\n",
    "        \"\"\"\n",
    "        h = tf.reshape(h, [-1, 10 * 16])\n",
    "        with tf.variable_scope('decoder', reuse=reuse):\n",
    "            weights = []\n",
    "            for i in range(len(num_h) - 1):\n",
    "                w = tf.get_variable(\n",
    "                    'wfc%d' % i, [num_h[i], num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                b = tf.get_variable(\n",
    "                    'bfc%d' % i, [num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                weights.append((w, b))\n",
    "                if i < len(num_h) - 2:\n",
    "                    h = tf.nn.relu(tf.add(tf.matmul(h, w), b))\n",
    "                else:\n",
    "                    h = tf.nn.sigmoid(tf.add(tf.matmul(h, w), b))\n",
    "        x_rec = tf.reshape(h, [-1, 28, 28, 1])\n",
    "        return x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:31.935607Z",
     "start_time": "2018-04-23T23:34:31.933154Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "is_multi_mnist = True\n",
    "is_shift_ag = True\n",
    "irun = 0\n",
    "steps = 3000\n",
    "lr_find = False\n",
    "lr_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first try to find the best lr by increasing it by every iter and see at what iter the corresponding lr is doing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:23:02.900184Z",
     "start_time": "2018-04-23T23:23:02.898209Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = True\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:25:06.442968Z",
     "start_time": "2018-04-23T23:23:03.209619Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "    \n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run([net.loss, net.loss_rec, net.accuracy, net.train], feed_dict={net.x: X, net.y: Y, net.on_train:True ,net.lr: lr})\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5,1e-2,steps)[2]-np.linspace(1e-5,1e-2,steps)[1]   \n",
    "        \n",
    "    else:    \n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST)\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:27:44.544374Z",
     "start_time": "2018-04-23T23:27:44.243658Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(lr_list,loss_list);\n",
    "plt.xticks(np.linspace(0.0001,0.009,25));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the figure above, we are going to let lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:40.105337Z",
     "start_time": "2018-04-23T23:34:40.101800Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = False\n",
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:34:40.508929Z",
     "start_time": "2018-04-23T23:34:40.506080Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T23:38:53.557837Z",
     "start_time": "2018-04-23T23:34:41.167439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 30.13177 0.1953125 0.1796875 1.705855131149292s per epoch\n",
      "100 2.433554 0.265625 0.296875 0.048009634017944336s per epoch\n",
      "200 1.9288659 0.203125 0.3203125 0.046990394592285156s per epoch\n",
      "300 1.4324812 0.3359375 0.3359375 0.04840850830078125s per epoch\n",
      "400 1.0698477 0.3828125 0.3359375 0.047640323638916016s per epoch\n",
      "500 1.0017887 0.21875 0.3046875 0.04743361473083496s per epoch\n",
      "600 1.0963323 0.3671875 0.359375 0.04785513877868652s per epoch\n",
      "700 1.0566791 0.3515625 0.3828125 0.046582937240600586s per epoch\n",
      "800 0.91935503 0.453125 0.296875 0.04712533950805664s per epoch\n",
      "900 0.93852246 0.5234375 0.40625 0.04722094535827637s per epoch\n",
      "Model Saved!\n",
      "1000 1.1700687 0.4921875 0.4375 0.047728538513183594s per epoch\n",
      "1100 0.9657382 0.40625 0.4140625 0.046988487243652344s per epoch\n",
      "1200 0.91111314 0.3984375 0.484375 0.04815173149108887s per epoch\n",
      "1300 0.79626256 0.53125 0.5859375 0.046970367431640625s per epoch\n",
      "1400 0.88984126 0.4140625 0.2421875 0.04828476905822754s per epoch\n",
      "1500 1.078676 0.4140625 0.3828125 0.04786968231201172s per epoch\n",
      "1600 0.8294409 0.4921875 0.4609375 0.048792123794555664s per epoch\n",
      "1700 0.8705731 0.46875 0.40625 0.04768943786621094s per epoch\n",
      "1800 0.8299127 0.53125 0.3515625 0.04795575141906738s per epoch\n",
      "1900 0.9607996 0.4765625 0.4765625 0.04840207099914551s per epoch\n",
      "Model Saved!\n",
      "2000 0.8218757 0.4921875 0.4296875 0.04834794998168945s per epoch\n",
      "2100 0.8557939 0.421875 0.453125 0.047734975814819336s per epoch\n",
      "2200 0.785717 0.4765625 0.4453125 0.04844546318054199s per epoch\n",
      "2300 0.86886 0.59375 0.453125 0.04777050018310547s per epoch\n",
      "2400 0.74142796 0.5703125 0.4609375 0.047835350036621094s per epoch\n",
      "2500 0.76861787 0.5234375 0.5390625 0.05873465538024902s per epoch\n",
      "2600 0.81323427 0.5078125 0.609375 0.04843878746032715s per epoch\n",
      "2700 0.822111 0.46875 0.4609375 0.04837632179260254s per epoch\n",
      "2800 0.75501406 0.578125 0.4453125 0.04698348045349121s per epoch\n",
      "2900 0.7625885 0.53125 0.4296875 0.048699378967285156s per epoch\n",
      "Model Saved!\n",
      "3000 0.7691671 0.5859375 0.484375 0.04831266403198242s per epoch\n",
      "3100 0.8221163 0.546875 0.4375 0.047162532806396484s per epoch\n",
      "3200 0.6745632 0.640625 0.578125 0.04797196388244629s per epoch\n",
      "3300 0.7987107 0.546875 0.53125 0.047063350677490234s per epoch\n",
      "3400 0.9877411 0.46875 0.3046875 0.047987937927246094s per epoch\n",
      "3500 0.6967796 0.6328125 0.625 0.05065727233886719s per epoch\n",
      "3600 0.71542877 0.59375 0.625 0.04845738410949707s per epoch\n",
      "3700 0.7753931 0.5546875 0.4453125 0.047582149505615234s per epoch\n",
      "3800 0.66010886 0.5546875 0.421875 0.04741406440734863s per epoch\n",
      "3900 0.6684855 0.5859375 0.484375 0.04761147499084473s per epoch\n",
      "Model Saved!\n",
      "4000 0.7168723 0.609375 0.5078125 0.048456430435180664s per epoch\n",
      "4100 0.7035631 0.59375 0.5546875 0.04824972152709961s per epoch\n",
      "4200 0.7821582 0.484375 0.5 0.04803633689880371s per epoch\n",
      "4300 0.77652967 0.5625 0.59375 0.049048423767089844s per epoch\n",
      "4400 0.71829635 0.6171875 0.5390625 0.04825162887573242s per epoch\n",
      "4500 0.725862 0.5703125 0.3125 0.04801821708679199s per epoch\n",
      "4600 0.7482604 0.4921875 0.2734375 0.047728538513183594s per epoch\n",
      "4700 0.6124346 0.71875 0.4609375 0.04791545867919922s per epoch\n",
      "4800 0.6693812 0.625 0.609375 0.04871726036071777s per epoch\n",
      "4900 0.745322 0.625 0.4921875 0.04969954490661621s per epoch\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#For model saving\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    a = time.time()\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "\n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True,\n",
    "                net.lr: lr\n",
    "            })\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5, 1e-2, steps)[2] - np.linspace(\n",
    "            1e-5, 1e-2, steps)[1]\n",
    "\n",
    "    else:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        b = time.time()\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST, '{}s per epoch'.format(b - a))\n",
    "\n",
    "        if (irun + 1) % 1000 == 0:\n",
    "            saver.save(sess, \"./checkpoint_CNN/MyModel\")\n",
    "            print('Model Saved!')\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
