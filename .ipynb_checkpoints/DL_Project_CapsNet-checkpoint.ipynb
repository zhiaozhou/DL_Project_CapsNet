{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:32:39.242693Z",
     "start_time": "2018-04-11T19:32:37.482539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:32:39.272357Z",
     "start_time": "2018-04-11T19:32:39.260329Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment the images\n",
    "def augmentation(x, max_offset=2):\n",
    "    bz, h, w, c = x.shape\n",
    "    bg = np.zeros([bz, w + 2 * max_offset, h + 2 * max_offset, c])\n",
    "    offsets = np.random.randint(0, 2 * max_offset + 1, 2)\n",
    "    #shift\n",
    "    bg[:, offsets[0]:offsets[0] + h, offsets[1]:offsets[1] + w, :] = x\n",
    "    return bg[:, max_offset:max_offset + h, max_offset:max_offset + w, :]\n",
    "\n",
    "#mini-batch for single digit training set\n",
    "def mnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        # the output is a batch of train set, with 28*28*3 for each pic and 10*3 label for corresponding pic. Shift is possible.\n",
    "\n",
    "#mini-batch for single digit test set\n",
    "def mnist_test_iter(iters=1000, batch_size=32, is_shift_ag=False):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.test.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        \n",
    "#mini-batch for overlapping digit training set\n",
    "def multimnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch1 = mnist.train.next_batch(batch_size)\n",
    "        batch2 = mnist.train.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "\n",
    "#mini-batch for overlapping digit test set\n",
    "def multimnist_test_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        #two batch at one iter\n",
    "        batch1 = mnist.test.next_batch(batch_size)\n",
    "        batch2 = mnist.test.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        #overlapping\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "        #size of result is 32*28*28*3, here data in same pos of pics with same index, will be put into one inner array\n",
    "        #sequence of shift and concatenate is reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:32:39.322344Z",
     "start_time": "2018-04-11T19:32:39.289947Z"
    }
   },
   "outputs": [],
   "source": [
    "# A CapsNet class is initiated here to assemble the process of prediction and validation.\n",
    "# 1. The input is a batch of pics, we need to split the input into 3 different batches\n",
    "# 2. Use get_CapsNet function\n",
    "# 2.1 to reach the output layer, with two hidden layer\n",
    "# 2.2 use process of dynamic routing, do it in iteration, update the output vector\n",
    "# 3. Use get_mlp_decoder function\n",
    "# 3.1 for each predicted output and real label, use get_mlp_decoder to reconstruct the input pics\n",
    "# 4. Cal the difference between reconstructed pics and real pics. Use function to cal the loss and accuracy.\n",
    "# when we init a class, and input the batches, we could acquire the accuracy from classâ€™s variables.\n",
    "\n",
    "class CapsNet(object):\n",
    "    def __init__(self,\n",
    "                 routing_iterations=3,\n",
    "                 batch_size=128,\n",
    "                 is_multi_mnist=True,\n",
    "                 steps=5000,\n",
    "                 norm=True,\n",
    "                 lr_find=False):\n",
    "        \"\"\"\n",
    "        routing_iterations: iterations for routing in CapsNet\n",
    "        batch_size: data size for every batch\n",
    "        is_multi_mnist: if it's for single or overlapping image\n",
    "        steps: epochs \n",
    "        norm: if batch_normalization or not\n",
    "        \"\"\"\n",
    "        self.iterations = routing_iterations\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Single or overlapping image\n",
    "        self.is_multi_mnist = float(is_multi_mnist)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 10, 3])\n",
    "        \n",
    "        if lr_find:\n",
    "            self.lr = tf.placeholder(tf.float32)\n",
    "        else:\n",
    "            #use a exponentially decayed learninig rate\n",
    "            global_step = tf.Variable(0)\n",
    "            lr = tf.train.exponential_decay(\n",
    "                0.00075, global_step, steps / 10, 0.96, staircase=False)\n",
    "        self.norm = norm\n",
    "        self.on_train = tf.placeholder(tf.bool)\n",
    "\n",
    "        x_composed, x_a, x_b = tf.split(self.x, num_or_size_splits=3, axis=3)\n",
    "        y_composed, y_a, y_b = tf.split(self.y, num_or_size_splits=3, axis=2)\n",
    "    \n",
    "        #if not overlapping, mask = tf.ones_like(y_composed[:,0,0])\n",
    "        #if overlapping: mask = tf.reduce_sum(y_composed, axis=[1,2]) - 1.0\n",
    "        #for not overlapping: ones_like will generate the array of 1 the same size as input array. Here y_composed[:,0,0], each pic choose only 1 pos, therefore, it is a 1 dimension vector, the size equals batch_size.\n",
    "        #for overlapping: reduce_sum will sum all num in a range. Here, we choose [1, 2], which is all label for a particular pic. Therefore, reduce_sum here will sum label for each pic in the batch, will represent the num of digits in each pic.\n",
    "        valid_mask = self.is_multi_mnist * (tf.reduce_sum(y_composed, axis=[1,2]) - 1.0) \\\n",
    "                      + (1.0 - self.is_multi_mnist) * tf.ones_like(y_composed[:,0,0])\n",
    "        \n",
    "        #reg_term is the penalty term\n",
    "        v_digit,reg_term = self.get_CapsNet(x_composed, self.norm, self.on_train)\n",
    "\n",
    "        length_v = tf.reduce_sum(v_digit**2.0, axis=-1)**0.5\n",
    "\n",
    "        x_rec_a = self.get_mlp_decoder(v_digit * y_a)\n",
    "        x_rec_b = self.get_mlp_decoder(v_digit * y_b, reuse=True)\n",
    "        loss_rec_a = tf.reduce_sum((x_rec_a - x_a)**2.0, axis=[1, 2, 3])\n",
    "        loss_rec_b = tf.reduce_sum((x_rec_b - x_b)**2.0, axis=[1, 2, 3])\n",
    "        self.loss_rec = (loss_rec_a + loss_rec_b) / 2.0\n",
    "        \n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            y_composed[:, :, 0] * tf.maximum(0.0, 0.9 - length_v)**2.0 + 0.5 *\n",
    "            (1.0 - y_composed[:, :, 0]) * tf.maximum(0.0, length_v - 0.1)**2.0,\n",
    "            axis=-1)\n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            self.loss_cls * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_cls: batch_size, valid_mask: _batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #sum2: num of digits for all pics in the batch\n",
    "        #cal the loss percentage considering y_composed (real label)\n",
    "        \n",
    "        self.loss_rec = tf.reduce_sum(\n",
    "            self.loss_rec * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_rec: batch_size, valid_mask: batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #cal the loss percentage considering prediction from x_composed, x_a, x_b\n",
    "        \n",
    "        #loss with the penalty term\n",
    "        self.loss = self.loss_cls + 0.0005 * self.loss_rec + reg_term\n",
    "        \n",
    "        #adam optimizer\n",
    "        if lr_find:\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "        else:\n",
    "            self.train = tf.train.AdamOptimizer(\n",
    "                learning_rate=lr).minimize(\n",
    "                    self.loss, global_step=global_step)\n",
    "\n",
    "        #accuracy for single and overlapping training data\n",
    "        if is_multi_mnist:\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_a), 1),k=2),tf.float32))+\\\n",
    "                            tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_b), 1),k=2),tf.float32))\n",
    "            self.accuracy /= 2.0\n",
    "        else:\n",
    "            correct_prediction = tf.equal(\n",
    "                tf.argmax(y_composed[:, :, 0], 1), tf.argmax(length_v, 1))\n",
    "            self.accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def get_CapsNet(self, x, norm, on_train, reuse=False):\n",
    "        \"\"\"\n",
    "        norm: to use batch-normalization or not\n",
    "        on_train: if it's for train or test\n",
    "        \"\"\"\n",
    "        #Two conv layers and a capsule layer\n",
    "        with tf.variable_scope('CapsNet', reuse=reuse):\n",
    "            wconv1 = tf.get_variable(\n",
    "                'wconv1', [9, 9, 1, 256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv1 = tf.get_variable(\n",
    "                'bconv1', [256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wconv2 = tf.get_variable(\n",
    "                'wconv2', [9, 9, 256, 8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv2 = tf.get_variable(\n",
    "                'bconv2', [8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wcap = tf.get_variable(\n",
    "                'wcap', [1, 6, 6, 32, 8, 10, 16],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b = tf.get_variable(\n",
    "                'coupling_coefficient_logits', [1, 6, 6, 32, 1, 10, 1],\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        #use stop_gradient for debug\n",
    "        c = tf.stop_gradient(tf.nn.softmax(b, axis=5))\n",
    "        \n",
    "        #L2-regularization\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv1)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv2)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wcap)\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "        \n",
    "        if norm:\n",
    "            # BN for the first input\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                x,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                \"\"\"\n",
    "                update mean and variance using moving average\n",
    "                \"\"\"\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "            \n",
    "            # if it's for test, then don't update mean and var, instead use the fc_mean and fc_var that already calculated\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            x = tf.nn.batch_normalization(x, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        conv1 = tf.nn.conv2d(x, wconv1, [1, 1, 1, 1], padding='VALID') + bconv1\n",
    "\n",
    "        if norm:\n",
    "            # BN for the first conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv1,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv1 = tf.nn.batch_normalization(conv1, mean, var, shift, scale,\n",
    "                                              epsilon)\n",
    "\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "        s_primary = tf.nn.conv2d(\n",
    "            conv1, wconv2, [1, 2, 2, 1], padding='VALID') + bconv2\n",
    "\n",
    "        if norm:\n",
    "            # BN for the second conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                s_primary,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            s_primary = tf.nn.batch_normalization(s_primary, mean, var, shift,\n",
    "                                                  scale, epsilon)\n",
    "\n",
    "        s_primary = tf.reshape(s_primary, [-1, 6, 6, 32, 8, 1, 1])\n",
    "        #change form from batch_size*6*6*256 into -1*6*6*32*8*1*1. For input of capsule, it contains 6*6*32 vectors, each vector has 8 elements. We could consider it as reshape the 256 output layer into 8 groups, each group contains 32 layer. Put 8 groups parallel and each vector is the pix in same positions in 8 groups. \n",
    "        #the use of 1, 1 will make it easy to cal when we do u*wcap in the following step. (* is the multiply by elements in corresponding pos) (expand automatically, but we need to keep same dimensions first)\n",
    "\n",
    "        v_primary = self.squash(s_primary, axis=4)\n",
    "\n",
    "        #CAPSNET\n",
    "        u = v_primary #input of capsule\n",
    "        u_ = tf.reduce_sum(u * wcap, axis=[4], keepdims=True)\n",
    "        s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "        v = self.squash(s, axis=-1)\n",
    "\n",
    "        if norm:\n",
    "            # BN for the capsule layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                v,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            v = tf.nn.batch_normalization(v, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        for i in range(self.iterations - 1):\n",
    "            b += tf.reduce_sum(u_ * v, axis=-1, keepdims=True)\n",
    "            c = tf.nn.softmax(b, axis=5)\n",
    "            s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "            v = self.squash(s, axis=-1) #get the correct v\n",
    "\n",
    "        v_digit = tf.squeeze(v)\n",
    "\n",
    "        return v_digit,reg_term\n",
    "\n",
    "    def get_mlp_decoder(self, h, num_h=[10 * 16, 512, 1024, 784], reuse=False):\n",
    "        \"\"\"\n",
    "        restruction the input images: 160 -> 512 -> 1024 -> 784\n",
    "        \"\"\"\n",
    "        h = tf.reshape(h, [-1, 10 * 16])\n",
    "        with tf.variable_scope('decoder', reuse=reuse):\n",
    "            weights = []\n",
    "            for i in range(len(num_h) - 1):\n",
    "                w = tf.get_variable(\n",
    "                    'wfc%d' % i, [num_h[i], num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                b = tf.get_variable(\n",
    "                    'bfc%d' % i, [num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                weights.append((w, b))\n",
    "                if i < len(num_h) - 2:\n",
    "                    h = tf.nn.relu(tf.add(tf.matmul(h, w), b))\n",
    "                else:\n",
    "                    h = tf.nn.sigmoid(tf.add(tf.matmul(h, w), b))\n",
    "        x_rec = tf.reshape(h, [-1, 28, 28, 1])\n",
    "        return x_rec\n",
    "\n",
    "    def squash(self, s, axis=-1):\n",
    "        length_s = tf.reduce_sum(s**2.0, axis=axis, keepdims=True)**0.5\n",
    "        v = s * length_s / (1.0 + length_s**2.0) #shorten the length of each vector, make the length a little shorter than 1. Non-linear. To avoid the existence of 0 vector.\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:32:39.342245Z",
     "start_time": "2018-04-11T19:32:39.339403Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "is_multi_mnist = True\n",
    "is_shift_ag = True\n",
    "irun = 0\n",
    "steps = 3000\n",
    "lr_find = False\n",
    "lr_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first try to find the best lr by increasing it by every iter and see at what iter the corresponding lr is doing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:32:32.027961Z",
     "start_time": "2018-04-09T01:32:32.024607Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = True\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:19.388102Z",
     "start_time": "2018-04-09T01:32:32.721926Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "    \n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run([net.loss, net.loss_rec, net.accuracy, net.train], feed_dict={net.x: X, net.y: Y, net.on_train:True ,net.lr: lr})\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5,1e-2,steps)[2]-np.linspace(1e-5,1e-2,steps)[1]   \n",
    "        \n",
    "    else:    \n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST)\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:32.033332Z",
     "start_time": "2018-04-09T01:36:31.274615Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(lr_list,loss_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the figure above, we are going to let lr = 0.00075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:32:43.865952Z",
     "start_time": "2018-04-11T19:32:43.862613Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = False\n",
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T19:40:36.928854Z",
     "start_time": "2018-04-11T19:32:44.563411Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 1.6246809 0.265625 0.3046875\n",
      "100 0.67166036 0.609375 0.625\n",
      "200 0.5254948 0.7578125 0.6875\n",
      "300 0.4954794 0.828125 0.703125\n",
      "400 0.5796177 0.6796875 0.6015625\n",
      "500 0.49871352 0.78125 0.8125\n",
      "600 0.41876918 0.7890625 0.8046875\n",
      "700 0.4307312 0.7734375 0.6484375\n",
      "800 0.4099663 0.8359375 0.6328125\n",
      "900 0.3699326 0.8203125 0.7890625\n",
      "Model Saved!\n",
      "1000 0.3847624 0.8125 0.7734375\n",
      "1100 0.44862935 0.7890625 0.7109375\n",
      "1200 0.34816462 0.8515625 0.84375\n",
      "1300 0.38980687 0.8046875 0.8046875\n",
      "1400 0.33247244 0.859375 0.8046875\n",
      "1500 0.32955864 0.828125 0.828125\n",
      "1600 0.37546968 0.828125 0.890625\n",
      "1700 0.4293028 0.7578125 0.8125\n",
      "1800 0.34960744 0.7890625 0.8671875\n",
      "1900 0.2727844 0.875 0.7109375\n",
      "Model Saved!\n",
      "2000 0.31958053 0.875 0.7109375\n",
      "2100 0.2888675 0.8515625 0.7109375\n",
      "2200 0.3072666 0.8359375 0.78125\n",
      "2300 0.27674925 0.9296875 0.859375\n",
      "2400 0.30285394 0.8515625 0.796875\n",
      "2500 0.36321712 0.828125 0.828125\n",
      "2600 0.28020328 0.8828125 0.71875\n",
      "2700 0.2246955 0.9296875 0.8828125\n",
      "2800 0.30946946 0.875 0.828125\n",
      "2900 0.3358432 0.8515625 0.734375\n",
      "Model Saved!\n",
      "3000 0.27058017 0.8984375 0.78125\n",
      "3100 0.38606468 0.78125 0.75\n",
      "3200 0.34907284 0.8359375 0.7734375\n",
      "3300 0.28809565 0.8515625 0.8125\n",
      "3400 0.33457816 0.828125 0.8359375\n",
      "3500 0.23673853 0.921875 0.6796875\n",
      "3600 0.33556074 0.8359375 0.84375\n",
      "3700 0.28632504 0.859375 0.859375\n",
      "3800 0.26706618 0.8828125 0.8125\n",
      "3900 0.25767505 0.890625 0.8828125\n",
      "Model Saved!\n",
      "4000 0.21750742 0.921875 0.765625\n",
      "4100 0.27803516 0.84375 0.8203125\n",
      "4200 0.23841676 0.9140625 0.84375\n",
      "4300 0.2255644 0.90625 0.7890625\n",
      "4400 0.35496154 0.8125 0.796875\n",
      "4500 0.33011347 0.84375 0.796875\n",
      "4600 0.27737933 0.8984375 0.828125\n",
      "4700 0.33450425 0.828125 0.640625\n",
      "4800 0.29104167 0.8984375 0.921875\n",
      "4900 0.2999329 0.84375 0.6796875\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#For model saving\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "    \n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run([net.loss, net.loss_rec, net.accuracy, net.train], feed_dict={net.x: X, net.y: Y, net.on_train:True ,net.lr: lr})\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5,1e-2,steps)[2]-np.linspace(1e-5,1e-2,steps)[1]   \n",
    "        \n",
    "    else:    \n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST)\n",
    "        \n",
    "        if (irun+1) % 1000 ==0:\n",
    "            saver.save(sess,\"./checkpoint_dir/MyModel\")\n",
    "            print('Model Saved!')\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
