{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:01.584007Z",
     "start_time": "2018-04-13T03:41:59.840798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:01.620733Z",
     "start_time": "2018-04-13T03:42:01.610013Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment the images\n",
    "def augmentation(x, max_offset=2):\n",
    "    bz, h, w, c = x.shape\n",
    "    bg = np.zeros([bz, w + 2 * max_offset, h + 2 * max_offset, c])\n",
    "    offsets = np.random.randint(0, 2 * max_offset + 1, 2)\n",
    "    #shift\n",
    "    bg[:, offsets[0]:offsets[0] + h, offsets[1]:offsets[1] + w, :] = x\n",
    "    return bg[:, max_offset:max_offset + h, max_offset:max_offset + w, :]\n",
    "\n",
    "#mini-batch for single digit training set\n",
    "def mnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        # the output is a batch of train set, with 28*28*3 for each pic and 10*3 label for corresponding pic. Shift is possible.\n",
    "\n",
    "#mini-batch for single digit test set\n",
    "def mnist_test_iter(iters=1000, batch_size=32, is_shift_ag=False):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch = mnist.test.next_batch(batch_size)\n",
    "        images = batch[0].reshape([batch_size, 28, 28, 1])\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "        yield augmentation(images, max_offset), np.stack(\n",
    "            [batch[1]] * 3, axis=-1)\n",
    "        \n",
    "#mini-batch for overlapping digit training set\n",
    "def multimnist_train_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        batch1 = mnist.train.next_batch(batch_size)\n",
    "        batch2 = mnist.train.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "\n",
    "#mini-batch for overlapping digit test set\n",
    "def multimnist_test_iter(iters=1000, batch_size=32, is_shift_ag=True):\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    max_offset = int(is_shift_ag) * 2\n",
    "    for i in range(iters):\n",
    "        #two batch at one iter\n",
    "        batch1 = mnist.test.next_batch(batch_size)\n",
    "        batch2 = mnist.test.next_batch(batch_size)\n",
    "        images1 = augmentation(batch1[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        images2 = augmentation(batch2[0].reshape([batch_size, 28, 28, 1]),\n",
    "                               max_offset)\n",
    "        #overlapping\n",
    "        images = np.logical_or(images1, images2).astype(np.float32)\n",
    "        images = np.concatenate([images, images1, images2], axis=-1)\n",
    "        y1, y2 = batch1[1], batch2[1]\n",
    "        y0 = np.logical_or(y1, y2).astype(np.float32)\n",
    "        yield images, np.stack([y0, y1, y2], axis=-1)\n",
    "        #size of result is 32*28*28*3, here data in same pos of pics with same index, will be put into one inner array\n",
    "        #sequence of shift and concatenate is reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:01.677561Z",
     "start_time": "2018-04-13T03:42:01.647073Z"
    }
   },
   "outputs": [],
   "source": [
    "# A CapsNet class is initiated here to assemble the process of prediction and validation.\n",
    "# 1. The input is a batch of pics, we need to split the input into 3 different batches\n",
    "# 2. Use get_CapsNet function\n",
    "# 2.1 to reach the output layer, with two hidden layer\n",
    "# 2.2 use process of dynamic routing, do it in iteration, update the output vector\n",
    "# 3. Use get_mlp_decoder function\n",
    "# 3.1 for each predicted output and real label, use get_mlp_decoder to reconstruct the input pics\n",
    "# 4. Cal the difference between reconstructed pics and real pics. Use function to cal the loss and accuracy.\n",
    "# when we init a class, and input the batches, we could acquire the accuracy from classâ€™s variables.\n",
    "\n",
    "class CapsNet(object):\n",
    "    def __init__(self,\n",
    "                 routing_iterations=3,\n",
    "                 batch_size=128,\n",
    "                 is_multi_mnist=True,\n",
    "                 steps=5000,\n",
    "                 norm=True,\n",
    "                 lr_find=False):\n",
    "        \"\"\"\n",
    "        routing_iterations: iterations for routing in CapsNet\n",
    "        batch_size: data size for every batch\n",
    "        is_multi_mnist: if it's for single or overlapping image\n",
    "        steps: epochs \n",
    "        norm: if batch_normalization or not\n",
    "        \"\"\"\n",
    "        self.iterations = routing_iterations\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Single or overlapping image\n",
    "        self.is_multi_mnist = float(is_multi_mnist)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 10, 3])\n",
    "        \n",
    "        if lr_find:\n",
    "            self.lr = tf.placeholder(tf.float32)\n",
    "        else:\n",
    "            #use a exponentially decayed learninig rate\n",
    "            global_step = tf.Variable(0)\n",
    "            lr = tf.train.exponential_decay(\n",
    "                0.00075, global_step, steps / 10, 0.96, staircase=False)\n",
    "        self.norm = norm\n",
    "        self.on_train = tf.placeholder(tf.bool)\n",
    "\n",
    "        x_composed, x_a, x_b = tf.split(self.x, num_or_size_splits=3, axis=3)\n",
    "        y_composed, y_a, y_b = tf.split(self.y, num_or_size_splits=3, axis=2)\n",
    "    \n",
    "        #if not overlapping, mask = tf.ones_like(y_composed[:,0,0])\n",
    "        #if overlapping: mask = tf.reduce_sum(y_composed, axis=[1,2]) - 1.0\n",
    "        #for not overlapping: ones_like will generate the array of 1 the same size as input array. Here y_composed[:,0,0], each pic choose only 1 pos, therefore, it is a 1 dimension vector, the size equals batch_size.\n",
    "        #for overlapping: reduce_sum will sum all num in a range. Here, we choose [1, 2], which is all label for a particular pic. Therefore, reduce_sum here will sum label for each pic in the batch, will represent the num of digits in each pic.\n",
    "        valid_mask = self.is_multi_mnist * (tf.reduce_sum(y_composed, axis=[1,2]) - 1.0) \\\n",
    "                      + (1.0 - self.is_multi_mnist) * tf.ones_like(y_composed[:,0,0])\n",
    "        \n",
    "        #reg_term is the penalty term\n",
    "        v_digit,reg_term = self.get_CapsNet(x_composed, self.norm, self.on_train)\n",
    "\n",
    "        length_v = tf.reduce_sum(v_digit**2.0, axis=-1)**0.5\n",
    "\n",
    "        x_rec_a = self.get_mlp_decoder(v_digit * y_a)\n",
    "        x_rec_b = self.get_mlp_decoder(v_digit * y_b, reuse=True)\n",
    "        loss_rec_a = tf.reduce_sum((x_rec_a - x_a)**2.0, axis=[1, 2, 3])\n",
    "        loss_rec_b = tf.reduce_sum((x_rec_b - x_b)**2.0, axis=[1, 2, 3])\n",
    "        self.loss_rec = (loss_rec_a + loss_rec_b) / 2.0\n",
    "        \n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            y_composed[:, :, 0] * tf.maximum(0.0, 0.9 - length_v)**2.0 + 0.5 *\n",
    "            (1.0 - y_composed[:, :, 0]) * tf.maximum(0.0, length_v - 0.1)**2.0,\n",
    "            axis=-1)\n",
    "        self.loss_cls = tf.reduce_sum(\n",
    "            self.loss_cls * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_cls: batch_size, valid_mask: _batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #sum2: num of digits for all pics in the batch\n",
    "        #cal the loss percentage considering y_composed (real label)\n",
    "        \n",
    "        self.loss_rec = tf.reduce_sum(\n",
    "            self.loss_rec * valid_mask) / tf.reduce_sum(valid_mask)\n",
    "        #loss_rec: batch_size, valid_mask: batch_size\n",
    "        #sum1: loss for all pics in the batch\n",
    "        #cal the loss percentage considering prediction from x_composed, x_a, x_b\n",
    "        \n",
    "        #loss with the penalty term\n",
    "        self.loss = self.loss_cls + 0.0005 * self.loss_rec + reg_term\n",
    "        \n",
    "        #adam optimizer\n",
    "        if lr_find:\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "        else:\n",
    "            self.train = tf.train.AdamOptimizer(\n",
    "                learning_rate=lr).minimize(\n",
    "                    self.loss, global_step=global_step)\n",
    "\n",
    "        #accuracy for single and overlapping training data\n",
    "        if is_multi_mnist:\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_a), 1),k=2),tf.float32))+\\\n",
    "                            tf.reduce_mean(tf.cast(tf.nn.in_top_k(length_v,tf.argmax(tf.squeeze(y_b), 1),k=2),tf.float32))\n",
    "            self.accuracy /= 2.0\n",
    "        else:\n",
    "            correct_prediction = tf.equal(\n",
    "                tf.argmax(y_composed[:, :, 0], 1), tf.argmax(length_v, 1))\n",
    "            self.accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def get_CapsNet(self, x, norm, on_train, reuse=False):\n",
    "        \"\"\"\n",
    "        norm: to use batch-normalization or not\n",
    "        on_train: if it's for train or test\n",
    "        \"\"\"\n",
    "        #Two conv layers and a capsule layer\n",
    "        with tf.variable_scope('CapsNet', reuse=reuse):\n",
    "            wconv1 = tf.get_variable(\n",
    "                'wconv1', [9, 9, 1, 256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv1 = tf.get_variable(\n",
    "                'bconv1', [256],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wconv2 = tf.get_variable(\n",
    "                'wconv2', [9, 9, 256, 8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            bconv2 = tf.get_variable(\n",
    "                'bconv2', [8 * 32],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            wcap = tf.get_variable(\n",
    "                'wcap', [1, 6, 6, 32, 8, 10, 16],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b = tf.get_variable(\n",
    "                'coupling_coefficient_logits', [1, 6, 6, 32, 1, 10, 1],\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        #use stop_gradient for debug\n",
    "        c = tf.stop_gradient(tf.nn.softmax(b, axis=5))\n",
    "        \n",
    "        #L2-regularization\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv1)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wconv2)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, wcap)\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "\n",
    "        \n",
    "        if norm:\n",
    "            # BN for the first input\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                x,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                \"\"\"\n",
    "                update mean and variance using moving average\n",
    "                \"\"\"\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "            \n",
    "            # if it's for test, then don't update mean and var, instead use the fc_mean and fc_var that already calculated\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            x = tf.nn.batch_normalization(x, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        conv1 = tf.nn.conv2d(x, wconv1, [1, 1, 1, 1], padding='VALID') + bconv1\n",
    "\n",
    "        if norm:\n",
    "            # BN for the first conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                conv1,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            conv1 = tf.nn.batch_normalization(conv1, mean, var, shift, scale,\n",
    "                                              epsilon)\n",
    "\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "        s_primary = tf.nn.conv2d(\n",
    "            conv1, wconv2, [1, 2, 2, 1], padding='VALID') + bconv2\n",
    "\n",
    "        if norm:\n",
    "            # BN for the second conv layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                s_primary,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            s_primary = tf.nn.batch_normalization(s_primary, mean, var, shift,\n",
    "                                                  scale, epsilon)\n",
    "\n",
    "        s_primary = tf.reshape(s_primary, [-1, 6, 6, 32, 8, 1, 1])\n",
    "        #change form from batch_size*6*6*256 into -1*6*6*32*8*1*1. For input of capsule, it contains 6*6*32 vectors, each vector has 8 elements. We could consider it as reshape the 256 output layer into 8 groups, each group contains 32 layer. Put 8 groups parallel and each vector is the pix in same positions in 8 groups. \n",
    "        #the use of 1, 1 will make it easy to cal when we do u*wcap in the following step. (* is the multiply by elements in corresponding pos) (expand automatically, but we need to keep same dimensions first)\n",
    "\n",
    "        v_primary = self.squash(s_primary, axis=4)\n",
    "\n",
    "        #CAPSNET\n",
    "        u = v_primary #input of capsule\n",
    "        u_ = tf.reduce_sum(u * wcap, axis=[4], keepdims=True)\n",
    "        s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "        v = self.squash(s, axis=-1)\n",
    "\n",
    "        if norm:\n",
    "            # BN for the capsule layer\n",
    "            fc_mean, fc_var = tf.nn.moments(\n",
    "                v,\n",
    "                axes=[0, 1, 2],\n",
    "            )\n",
    "            scale = tf.Variable(tf.ones([1]))\n",
    "            shift = tf.Variable(tf.zeros([1]))\n",
    "            epsilon = 0.001\n",
    "            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "            def mean_var_with_update():\n",
    "                ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "\n",
    "            mean, var = tf.cond(\n",
    "                on_train, mean_var_with_update,\n",
    "                lambda: (ema.average(fc_mean), ema.average(fc_var)))\n",
    "            v = tf.nn.batch_normalization(v, mean, var, shift, scale, epsilon)\n",
    "\n",
    "        for i in range(self.iterations - 1):\n",
    "            b += tf.reduce_sum(u_ * v, axis=-1, keepdims=True)\n",
    "            c = tf.nn.softmax(b, axis=5)\n",
    "            s = tf.reduce_sum(u_ * c, axis=[1, 2, 3], keepdims=True)\n",
    "            v = self.squash(s, axis=-1) #get the correct v\n",
    "\n",
    "        v_digit = tf.squeeze(v)\n",
    "\n",
    "        return v_digit,reg_term\n",
    "\n",
    "    def get_mlp_decoder(self, h, num_h=[10 * 16, 512, 1024, 784], reuse=False):\n",
    "        \"\"\"\n",
    "        restruction the input images: 160 -> 512 -> 1024 -> 784\n",
    "        \"\"\"\n",
    "        h = tf.reshape(h, [-1, 10 * 16])\n",
    "        with tf.variable_scope('decoder', reuse=reuse):\n",
    "            weights = []\n",
    "            for i in range(len(num_h) - 1):\n",
    "                w = tf.get_variable(\n",
    "                    'wfc%d' % i, [num_h[i], num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                b = tf.get_variable(\n",
    "                    'bfc%d' % i, [num_h[i + 1]],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "                weights.append((w, b))\n",
    "                if i < len(num_h) - 2:\n",
    "                    h = tf.nn.relu(tf.add(tf.matmul(h, w), b))\n",
    "                else:\n",
    "                    h = tf.nn.sigmoid(tf.add(tf.matmul(h, w), b))\n",
    "        x_rec = tf.reshape(h, [-1, 28, 28, 1])\n",
    "        return x_rec\n",
    "\n",
    "    def squash(self, s, axis=-1):\n",
    "        length_s = tf.reduce_sum(s**2.0, axis=axis, keepdims=True)**0.5\n",
    "        v = s * length_s / (1.0 + length_s**2.0) #shorten the length of each vector, make the length a little shorter than 1. Non-linear. To avoid the existence of 0 vector.\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:01.707063Z",
     "start_time": "2018-04-13T03:42:01.704494Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "is_multi_mnist = True\n",
    "is_shift_ag = True\n",
    "irun = 0\n",
    "steps = 3000\n",
    "lr_find = False\n",
    "lr_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first try to find the best lr by increasing it by every iter and see at what iter the corresponding lr is doing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:32:32.027961Z",
     "start_time": "2018-04-09T01:32:32.024607Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = True\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:19.388102Z",
     "start_time": "2018-04-09T01:32:32.721926Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "    \n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run([net.loss, net.loss_rec, net.accuracy, net.train], feed_dict={net.x: X, net.y: Y, net.on_train:True ,net.lr: lr})\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5,1e-2,steps)[2]-np.linspace(1e-5,1e-2,steps)[1]   \n",
    "        \n",
    "    else:    \n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST)\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T01:36:32.033332Z",
     "start_time": "2018-04-09T01:36:31.274615Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(lr_list,loss_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the figure above, we are going to let lr = 0.00075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:05.653009Z",
     "start_time": "2018-04-13T03:42:05.649583Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_find = False\n",
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:42:05.968460Z",
     "start_time": "2018-04-13T03:42:05.965762Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T03:49:54.501280Z",
     "start_time": "2018-04-13T03:42:06.347297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 1.628147 0.1953125 0.3515625 1.9415197372436523s per epoch\n",
      "100 0.59912956 0.6953125 0.59375 0.09056496620178223s per epoch\n",
      "200 0.52137345 0.8046875 0.6953125 0.09038615226745605s per epoch\n",
      "300 0.55895627 0.7265625 0.78125 0.0896761417388916s per epoch\n",
      "400 0.47450686 0.7734375 0.7265625 0.09105134010314941s per epoch\n",
      "500 0.3720484 0.828125 0.75 0.09017324447631836s per epoch\n",
      "600 0.498544 0.765625 0.7265625 0.09156537055969238s per epoch\n",
      "700 0.41986126 0.8046875 0.734375 0.09174942970275879s per epoch\n",
      "800 0.36944285 0.796875 0.7890625 0.0905766487121582s per epoch\n",
      "900 0.45369655 0.7734375 0.625 0.0909428596496582s per epoch\n",
      "Model Saved!\n",
      "1000 0.46428728 0.75 0.8359375 0.09090280532836914s per epoch\n",
      "1100 0.3829682 0.8125 0.796875 0.09073877334594727s per epoch\n",
      "1200 0.36606973 0.8203125 0.734375 0.09024357795715332s per epoch\n",
      "1300 0.4026331 0.78125 0.6875 0.09027409553527832s per epoch\n",
      "1400 0.36891574 0.84375 0.765625 0.09017157554626465s per epoch\n",
      "1500 0.42818338 0.78125 0.8046875 0.09088253974914551s per epoch\n",
      "1600 0.28766865 0.8984375 0.7421875 0.09035682678222656s per epoch\n",
      "1700 0.36377233 0.84375 0.8515625 0.09053874015808105s per epoch\n",
      "1800 0.37902516 0.828125 0.828125 0.09004068374633789s per epoch\n",
      "1900 0.3355013 0.8359375 0.84375 0.09072685241699219s per epoch\n",
      "Model Saved!\n",
      "2000 0.30807215 0.859375 0.6640625 0.09096527099609375s per epoch\n",
      "2100 0.3419665 0.8671875 0.6484375 0.09073996543884277s per epoch\n",
      "2200 0.35655534 0.8125 0.8359375 0.0911259651184082s per epoch\n",
      "2300 0.30652615 0.84375 0.890625 0.08975362777709961s per epoch\n",
      "2400 0.314402 0.859375 0.859375 0.09117388725280762s per epoch\n",
      "2500 0.2844891 0.8671875 0.671875 0.1014711856842041s per epoch\n",
      "2600 0.27560762 0.8671875 0.8203125 0.09052729606628418s per epoch\n",
      "2700 0.2861729 0.8671875 0.8671875 0.09110450744628906s per epoch\n",
      "2800 0.30365473 0.859375 0.8828125 0.09105420112609863s per epoch\n",
      "2900 0.3456791 0.8515625 0.9140625 0.09109282493591309s per epoch\n",
      "Model Saved!\n",
      "3000 0.26986212 0.875 0.890625 0.09068799018859863s per epoch\n",
      "3100 0.2652867 0.90625 0.8046875 0.09019780158996582s per epoch\n",
      "3200 0.32426345 0.859375 0.7421875 0.09090709686279297s per epoch\n",
      "3300 0.31737128 0.8515625 0.796875 0.09133386611938477s per epoch\n",
      "3400 0.28396535 0.8671875 0.8984375 0.09313845634460449s per epoch\n",
      "3500 0.31463692 0.8671875 0.78125 0.090484619140625s per epoch\n",
      "3600 0.25616592 0.8984375 0.8828125 0.09013724327087402s per epoch\n",
      "3700 0.31282052 0.8515625 0.8046875 0.09080767631530762s per epoch\n",
      "3800 0.2882057 0.875 0.8046875 0.09177684783935547s per epoch\n",
      "3900 0.29622623 0.859375 0.8671875 0.09199714660644531s per epoch\n",
      "Model Saved!\n",
      "4000 0.22467442 0.90625 0.8671875 0.0923924446105957s per epoch\n",
      "4100 0.27698871 0.875 0.6875 0.0902407169342041s per epoch\n",
      "4200 0.2893545 0.8515625 0.875 0.09153056144714355s per epoch\n",
      "4300 0.28280327 0.8984375 0.6640625 0.0911250114440918s per epoch\n",
      "4400 0.24165037 0.8984375 0.7109375 0.0942540168762207s per epoch\n",
      "4500 0.28484383 0.8828125 0.828125 0.09042072296142578s per epoch\n",
      "4600 0.23890102 0.90625 0.7890625 0.09049463272094727s per epoch\n",
      "4700 0.29515272 0.8671875 0.8125 0.09050416946411133s per epoch\n",
      "4800 0.22570884 0.921875 0.8125 0.09075760841369629s per epoch\n",
      "4900 0.27015993 0.8671875 0.640625 0.09072756767272949s per epoch\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "if is_multi_mnist:\n",
    "    train_iter = multimnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = multimnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "else:\n",
    "    train_iter = mnist_train_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "    test_iter = mnist_test_iter(\n",
    "        iters=steps, batch_size=batch_size, is_shift_ag=True)\n",
    "\n",
    "net = CapsNet(is_multi_mnist=is_multi_mnist, steps=steps, lr_find=lr_find)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#For model saving\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    a = time.time()\n",
    "    X_TEST, Y_TEST = next(test_iter)\n",
    "\n",
    "    if lr_find:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True,\n",
    "                net.lr: lr\n",
    "            })\n",
    "        lr_list.append(lr)\n",
    "        loss_list.append(LS)\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC)\n",
    "        lr += np.linspace(1e-5, 1e-2, steps)[2] - np.linspace(\n",
    "            1e-5, 1e-2, steps)[1]\n",
    "\n",
    "    else:\n",
    "        LS, LS_REC, ACC, _ = sess.run(\n",
    "            [net.loss, net.loss_rec, net.accuracy, net.train],\n",
    "            feed_dict={\n",
    "                net.x: X,\n",
    "                net.y: Y,\n",
    "                net.on_train: True\n",
    "            })\n",
    "        ACC_TEST = sess.run(\n",
    "            net.accuracy,\n",
    "            feed_dict={\n",
    "                net.x: X_TEST,\n",
    "                net.y: Y_TEST,\n",
    "                net.on_train: False\n",
    "            })\n",
    "\n",
    "        b = time.time()\n",
    "        if irun % 100 == 0:\n",
    "            print(irun, LS, ACC, ACC_TEST, '{}s per epoch'.format(b - a))\n",
    "\n",
    "        if (irun + 1) % 1000 == 0:\n",
    "            saver.save(sess, \"./checkpoint_dir/MyModel\")\n",
    "            print('Model Saved!')\n",
    "\n",
    "    irun += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
